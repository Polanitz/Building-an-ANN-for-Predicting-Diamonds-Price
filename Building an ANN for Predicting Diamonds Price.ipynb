{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XzcMpOWVAJNO"
   },
   "source": [
    "## Roi Polanitzer learning how to predict anything using ANNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i9RL-QLkAJNS"
   },
   "source": [
    "## Before you begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I9vxdqcxAJNT"
   },
   "source": [
    "You can do this. Even if you don’t know the first thing about Neural Networks. Even if you’ve never written a line of code.\n",
    "It’s a lot easier if you’re good at math. No hassle though, if you’re not. I go through each line of code and try to explain the intuition behind it as simply as I can. Of course, it always helps to have some background knowledge, so if you need more help, check out the links at the end of this tutorial.\n",
    "\n",
    "To start all you need is\n",
    "- A computer/machine (windows/mac/linux) — (Even android might work)\n",
    "- Internet to download the requirements (don’t need it for the actual model)\n",
    "\n",
    "I would advise you to download Python 3.5+ and get anaconda Navigator if you don’t already have either installed.\n",
    "https://www.python.org/downloads/\n",
    "https://www.anaconda.com/distribution/\n",
    "— Also, get-pip\n",
    "\n",
    "Once you’re in the environment, pip install these packages:\n",
    "- Keras — pip install Keras or use tf.keras with Tensorflow 2.0\n",
    "- Sklearn — pip install -U scikit-learn\n",
    "- Pandas — Comes with anaconda or pip install pandas\n",
    "- Numpy — Comes with anaconda or pip install numpy\n",
    "- Matplotlib —Comes with anaconda or pip install matplotlib\n",
    "\n",
    "If you have all the above, you’re good to go. Once you have learned everything in this article, you will be able to build your own ANN in less than 10 minutes.\n",
    "If you’re facing any problems, feel free to contact me or leave a comment below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SXM5oj8NAJNU"
   },
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VaqCcOSTAJNV"
   },
   "source": [
    "## Perceptron/Neuron Overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2kqLsJq8AJNX"
   },
   "source": [
    "I created this project months ago when I was learning how various regression algorithms work within an Artificial Neural Network Model.\n",
    "An artificial neural network is an attempt to simulate the network of neurons that make up a human brain so that a computer will be able to learn things and make decisions in a human-like manner.\n",
    "Artificial Neurons are designed to imitate Neurons in our brains (which have Dendrites, axons, and tails). So in essence, we are creating a model that allows machines to think like humans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iop-faMkAJNZ"
   },
   "source": [
    "## Tensorflow Playground: Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iLG0C3KGAJNa"
   },
   "source": [
    "Artificial Neural Networks or ANNs (as I will now call them) are a subset of deep learning. Deep learning is usually associated with having a high number of input layers (equivalent to our senses that gather information), one or more hidden layers (that connect our input layers and perform computational algorithms to determine a probability or otherwise), and one or more output layers (something to predict). The output values can be continuous like in this case, or they can be binary (1 or 0), probabilistic, and even categorical.\n",
    "\n",
    "The way ANNs work is that they need to have certain weights assigned to each of the input variables. The hidden layers take a sum of the weighted average of these input layers and then apply a hidden activation function.\n",
    "\n",
    "There are many types of activation functions:\n",
    "Threshold (binary), Sigmoid (continuous), Rectifier (binary), Hyperbolic Tangent (continuous), SoftMax (Sigmoid for more than 1 output layers).\n",
    "\n",
    "You can play around with activation functions in the TensorFlow Playground. \n",
    "\n",
    "In this ANN model that we’ll be looking at, I used the Rectifier and the Sigmoid function. How did I use both? Here’s the intuition:\n",
    "\n",
    "Since my output variable is binary, I use the Rectifier function to classify that in my hidden layers, and then I use the Sigmoid function to determine the probability of whether the output will 1 or 0.\n",
    "The output value and the predicted value will generally be differentiated by a cost function (error).\n",
    "\n",
    "The goal is to minimize the loss function (cost) since this would bring the predicted value closer to the actual value. This is usually done by changing the weights of the input variables. Sometimes it can take a lot of time and computational power to calculate the actual or global cost function, and it makes sense to use a gradient descent approach to make this process much faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qTLkVx3sAJNb"
   },
   "source": [
    "## A Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dMI6TFnTAJNd"
   },
   "source": [
    "A Gradient descent uses the slope of a loss function at a certain point and tries to move downwards to find the lowest point of the function. However, if my function is not convex (with higher degrees freedom), I could end up at a local minimum rather than the global minimum of the function, and the network wouldn’t be as efficient.\n",
    "\n",
    "Therefore, I use the stochastic gradient descent method, which runs the function for each and every row and keeps updating the minimum of the cost function. This way, I have a higher chance of finding the global minimum. It is also actually faster than the gradient function since it is running smaller algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IijCO70qAJNe"
   },
   "source": [
    "# 2. Importing Data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XCV4f5EJAJNf"
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DiFkrRnLA5AJ"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('diamonds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "lDSOvvLRA74E",
    "outputId": "a7f5d750-6002-44e5-bb6a-f1e06d64e21c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table  price     x     y     z\n",
       "0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "3   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "4   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MgG8eAWYAJNv"
   },
   "outputs": [],
   "source": [
    "X = df[['carat','cut','color','clarity','depth','table','x','y','z']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BOfFHjTuAJN5"
   },
   "outputs": [],
   "source": [
    "y = df['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4AyaZfsjAJN_"
   },
   "source": [
    "## 2.1. Encoding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "BPuQaYk4AJOB",
    "outputId": "902d205a-df66-4c99-aae8-9ee0239f2797"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Encoding the Independent Variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X_1 = LabelEncoder() \n",
    "# Converting string labels into numbers.\n",
    "X['cut']=labelencoder_X_1.fit_transform(X['cut'])\n",
    "X['color']=labelencoder_X_1.fit_transform(X['color'])\n",
    "X['clarity']=labelencoder_X_1.fit_transform(X['clarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "64E1veu_AJOJ",
    "outputId": "7bcbd5de-8abe-4d73-98c6-40121affd40e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.29</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat  cut  color  clarity  depth  table     x     y     z\n",
       "0   0.23    2      1        3   61.5   55.0  3.95  3.98  2.43\n",
       "1   0.21    3      1        2   59.8   61.0  3.89  3.84  2.31\n",
       "2   0.23    1      1        4   56.9   65.0  4.05  4.07  2.31\n",
       "3   0.29    3      5        5   62.4   58.0  4.20  4.23  2.63\n",
       "4   0.31    1      6        3   63.3   58.0  4.34  4.35  2.75"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s-hcVLu7AJOQ"
   },
   "source": [
    "## 2.2. Splitting the Data into Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZjqALq_oAJOR"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Z07mcKE0AJOW",
    "outputId": "663da735-bfe0-44e4-953d-ac8482f2f502"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36139, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape #shape of X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KPS5hFkqAJOc",
    "outputId": "ce74df6e-c848-4228-ffb1-c4ccd4c31fbd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17801, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape #shape of X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QNigAR43AJOk",
    "outputId": "82ec3cbb-218b-41ca-925a-4556f27d94b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36139,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape #shape of y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ixliyyXSAJOs",
    "outputId": "6742f329-e6f9-4abf-9249-8c8f6e5c124a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17801,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape #shape of y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5gkSQ26MAJOz"
   },
   "source": [
    "## 2.3. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9xIu6EGVAJPQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1FCiYmC2AJPh"
   },
   "source": [
    "# 3. Importing Keras and Libraries for the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LVVqKutFAJPl"
   },
   "source": [
    "In this next section, I’m going to import Keras, which is the most important package I need for my ANN. I’ll use two classes that will help us define the ANN throughout the next section: Sequential and Dense. I won’t go into much detail about these classes, as the code will show what they are doing.\n",
    "\n",
    "Note: This is an old version of Keras that runs with backend Tensorflow 1. So if you installed Tensorflow 2, you can either downgrade or see the documentation to learn about any changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YnYqraqkAJPn",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jUWtq7VaAJQE"
   },
   "source": [
    "# 4. Building the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CZ12BYZKAJQF"
   },
   "source": [
    "The following steps will show how I went about building this artificial neural network:\n",
    "\n",
    "1. I will start by initializing the ANN using the sequential class\n",
    "2. I will add the input layer along with the first hidden layer.\n",
    "3. I will add another second hidden layer\n",
    "4. Now I will add the output layer.\n",
    "5. After adding the layers, I will compile the ANN model\n",
    "6. Finally, I will fit the ANN model to the training set. The model will then train itself based on the number of epochs I mention.\n",
    "7. Evaluation: I will create a predictor variable and a evaluate the results predicted by the machine and compare them with the actual results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SsDIc4BJAJQG"
   },
   "source": [
    "## 4.1. How to mathematically create an ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Df_8PZNbAJQH"
   },
   "source": [
    "1. Randomly initialize the weights to small numbers close to 0 (but not 0).\n",
    "2. Input the first observation of your dataset in the input layer. each feature in one input node.\n",
    "3. Forward-Propagation: from left to right. the neurons are activated in a way that the impact of each neuron’s activation is limited by the weights. Propagate the activations until getting the predicted result y.\n",
    "4. Compare the predicted result to the actual result. Measure the generated error.\n",
    "5. Back-Propagation: from right to left, the error is back-propagated. Update the weights according to how much they are responsible for the error. The learning rate decides by how much we update the weights.\n",
    "6. Repeat Steps 1 to 5 and update the weights after each observation (Reinforcement Learning). Or: Repeat Steps 1 to 5 but updates the weights only after a batch of observations (Batch Learning).\n",
    "7. When the whole training set passed through the ANN. that makes an epoch. Redo more epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nII1Cu2_AJQI"
   },
   "source": [
    "## 4.2. Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0CQJRcLeAJQJ"
   },
   "source": [
    "So there are actually 2 ways of initializing a model: either with Sequential Layers, like I did above, or the other method is to do it by a graph. The step below is essentially initializing the model as a sequence of layers.\n",
    "I create the object, which is basically the Artificial Neural Network that I’m about to build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8IFA1MwUAJQL"
   },
   "outputs": [],
   "source": [
    "#Initializing the Artificial Neural Network\n",
    "regressor = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7dJgf-O5AJQR"
   },
   "source": [
    "## 4.3. Adding the input layer and the first hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_dXjUqo0AJQS"
   },
   "source": [
    "In the steps below, I used the add method of the object to include the Dense class in the classifier object. Dense is essentially what is allowing us to create the layers for the model.\n",
    "\n",
    "Now, upon inspecting the Dense class, I can see there are a number of parameters, but as the mathematical steps above show us, I know already which parameters to input for the model.\n",
    "\n",
    "So I will use the following for the input layer and the first hidden layer:\n",
    "\n",
    "1. output_dim (output dimensions):\n",
    "This is simply the number of nodes I want to add in the hidden layer. I had previously learned that there is no right answer to this as experimentation can allow us to choose the right number of nodes, however, in this project, I took the average sum of the number of input and output layers, (9 + 1)/2 = 5.\n",
    "\n",
    "2. init (random initialization):\n",
    "This is the first step of the stochastic gradient descent. I need to initialize the weights to small numbers close to 0. The default value for this parameter is given as \"glorot_uniform\", but for simplification, I will use the \"uniform\" function, which will initialize the weights according to a uniform distribution.\n",
    "\n",
    "3. activation:\n",
    "As the name suggests, this is the activation function. In the first hidden layer, we want to use the rectifier activation function as I had mentioned in the introduction and that's why I input relu in this parameter.\n",
    "\n",
    "4. input_dim (input dimensions):\n",
    "This is the number of nodes in the input layer, which I already know is 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PaSnTRGaAJQT"
   },
   "outputs": [],
   "source": [
    "#Adding the input layer and a hidden layer\n",
    "regressor.add(Dense(6, activation='relu', kernel_initializer='glorot_uniform',input_dim=9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cHQD4vhVAJQY"
   },
   "source": [
    "## 4.4. Adding the second hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TNS4SeicAJQZ"
   },
   "source": [
    "For this hidden layer, I use the add method on the classifier object again.\n",
    "Using the dense function, I have a similar line of code, but the only difference is that this time there’s no need to specify the number of input layers since the model already knows how many layers to expect as I have already added the input layer to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lNsbq3dkAJQa"
   },
   "outputs": [],
   "source": [
    "#Adding second hidden layer\n",
    "regressor.add(Dense(5, activation='relu', kernel_initializer='glorot_uniform'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GP6Vwek_AJQe"
   },
   "source": [
    "## 4.5. Adding the output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6WRqOlBkAJQf"
   },
   "source": [
    "The final layer that we need to code into the model is the output layer. This process will again use the same add method with the Dense class.\n",
    "\n",
    "However, this time the number of nodes is changed to 1 since there is only oneoutput variable (1 or 0) in this layer, it will only have 1 node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aBMVS_SLAJQg"
   },
   "outputs": [],
   "source": [
    "#Adding output layer\n",
    "regressor.add(Dense(1, kernel_initializer='glorot_uniform', activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "urz5abSNAJQk"
   },
   "source": [
    "## 4.6. Compiling the ANN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m1HhKwMnAJQl"
   },
   "source": [
    "This time I use the Compile method on the classifier object and I input the following parameters:\n",
    "\n",
    "1. Optimizer: This the algorithm I want to use to find the optimal set of weights for the ANN model. The model’s layers have been built, but the weights have only been initialized. Therefore, it is important to use an optimizer to find the right combination of weights. rmsprop is one of the stochastic gradient descent algorithms, and that is the one I will use to find the optimal set of weights for this model.\n",
    "\n",
    "2. Loss: This corresponds to the loss function within the Stochastic gradient descent algorithm.The basic idea of this is that we need to optimize this loss function within the algorithm to find the optimal weights. For example, in linear regression, I use the sum-of-squares loss function to optimize the model. However, for the stochastic gradient descent, I use a logarithmic function known as root_mean_squared_error since we have a continuous output layer.\n",
    "\n",
    "3. Metrics: Just the criterion metric I use to evaluate the model. I can use the accuracy model (which sees correct predictions over total predictions). So, I input 'accuracy' in the metrics parameter. Since this is expecting a list, I would have to put it in square brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c3N5D-I3AJQm"
   },
   "outputs": [],
   "source": [
    "#Compiling the artificial neural network\n",
    "from keras.losses import mean_squared_error\n",
    "from keras import backend as K\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "regressor.compile(optimizer = \"rmsprop\", loss = root_mean_squared_error, metrics =[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kH-YWTLEAJQs"
   },
   "source": [
    "## 4.7. Fitting the ANN model to the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ddZ7fRHeAJQt"
   },
   "source": [
    "Now I will fit the model to the training dataset and will run the model to a certain number of epochs.\n",
    "\n",
    "I start by using the fit method to fit the regressor model to X_train and y_train. Then, I add two more parameters, which are the batch size and the number of epochs. If you look back at the beginning of this section, steps 6 and 7 refer to these parameters.\n",
    "\n",
    "In step 6, we can choose to update the weights after every observation or every batch. So for this step, I’ll use batches of 10 to update the weights.\n",
    "\n",
    "Step 7 tells us that we need to pass the whole training set to more than just 1 epoch. Epoch refers to one round of the entire dataset going through the ANN. I chose 90 epochs for this as choosing these values can be an experimentative process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "s6uwZF-AAJQv",
    "outputId": "ff06293e-c8fd-419c-caab-5dbbc4477195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/90\n",
      "36139/36139 [==============================] - 3s 82us/step - loss: 3619.4277 - accuracy: 1.9370e-04\n",
      "Epoch 2/90\n",
      "36139/36139 [==============================] - 3s 73us/step - loss: 1783.8033 - accuracy: 4.4274e-04\n",
      "Epoch 3/90\n",
      "36139/36139 [==============================] - 3s 74us/step - loss: 858.4288 - accuracy: 6.3643e-04\n",
      "Epoch 4/90\n",
      "36139/36139 [==============================] - 3s 74us/step - loss: 729.5380 - accuracy: 0.0011\n",
      "Epoch 5/90\n",
      "36139/36139 [==============================] - 3s 76us/step - loss: 701.3178 - accuracy: 0.0011\n",
      "Epoch 6/90\n",
      "36139/36139 [==============================] - 3s 80us/step - loss: 691.6130 - accuracy: 9.6848e-04\n",
      "Epoch 7/90\n",
      "36139/36139 [==============================] - 3s 93us/step - loss: 685.7424 - accuracy: 9.4081e-04\n",
      "Epoch 8/90\n",
      "36139/36139 [==============================] - 3s 89us/step - loss: 680.8000 - accuracy: 9.4081e-04\n",
      "Epoch 9/90\n",
      "36139/36139 [==============================] - 3s 79us/step - loss: 676.1388 - accuracy: 0.0013\n",
      "Epoch 10/90\n",
      "36139/36139 [==============================] - 3s 83us/step - loss: 671.5564 - accuracy: 0.0011\n",
      "Epoch 11/90\n",
      "36139/36139 [==============================] - 5s 130us/step - loss: 666.8611 - accuracy: 9.6848e-04\n",
      "Epoch 12/90\n",
      "36139/36139 [==============================] - 4s 112us/step - loss: 661.9078 - accuracy: 0.0011\n",
      "Epoch 13/90\n",
      "36139/36139 [==============================] - 3s 86us/step - loss: 656.9755 - accuracy: 0.0012\n",
      "Epoch 14/90\n",
      "36139/36139 [==============================] - 4s 105us/step - loss: 652.0443 - accuracy: 0.0012\n",
      "Epoch 15/90\n",
      "36139/36139 [==============================] - 3s 96us/step - loss: 646.9841 - accuracy: 0.0014\n",
      "Epoch 16/90\n",
      "36139/36139 [==============================] - 3s 84us/step - loss: 641.9789 - accuracy: 0.0013\n",
      "Epoch 17/90\n",
      "36139/36139 [==============================] - 3s 84us/step - loss: 636.9979 - accuracy: 9.9615e-04\n",
      "Epoch 18/90\n",
      "36139/36139 [==============================] - 3s 81us/step - loss: 631.8699 - accuracy: 0.0012\n",
      "Epoch 19/90\n",
      "36139/36139 [==============================] - 3s 80us/step - loss: 626.9205 - accuracy: 0.0014\n",
      "Epoch 20/90\n",
      "36139/36139 [==============================] - 3s 80us/step - loss: 622.4813 - accuracy: 0.0014\n",
      "Epoch 21/90\n",
      "36139/36139 [==============================] - 3s 80us/step - loss: 618.3206 - accuracy: 0.0013\n",
      "Epoch 22/90\n",
      "36139/36139 [==============================] - 3s 79us/step - loss: 614.6829 - accuracy: 0.0016\n",
      "Epoch 23/90\n",
      "36139/36139 [==============================] - 3s 82us/step - loss: 611.3246 - accuracy: 9.6848e-04\n",
      "Epoch 24/90\n",
      "36139/36139 [==============================] - 3s 79us/step - loss: 608.3643 - accuracy: 0.0013\n",
      "Epoch 25/90\n",
      "36139/36139 [==============================] - 3s 80us/step - loss: 605.1719 - accuracy: 0.0016\n",
      "Epoch 26/90\n",
      "36139/36139 [==============================] - 3s 80us/step - loss: 602.8203 - accuracy: 0.0014\n",
      "Epoch 27/90\n",
      "36139/36139 [==============================] - 3s 81us/step - loss: 600.2856 - accuracy: 0.0012\n",
      "Epoch 28/90\n",
      "36139/36139 [==============================] - 3s 80us/step - loss: 597.4850 - accuracy: 0.0013\n",
      "Epoch 29/90\n",
      "36139/36139 [==============================] - 3s 82us/step - loss: 595.3333 - accuracy: 0.0011\n",
      "Epoch 30/90\n",
      "36139/36139 [==============================] - 3s 79us/step - loss: 593.3746 - accuracy: 0.0014\n",
      "Epoch 31/90\n",
      "36139/36139 [==============================] - 4s 117us/step - loss: 591.8059 - accuracy: 8.8547e-04\n",
      "Epoch 32/90\n",
      "36139/36139 [==============================] - 5s 134us/step - loss: 590.6755 - accuracy: 0.0011\n",
      "Epoch 33/90\n",
      "36139/36139 [==============================] - 5s 141us/step - loss: 589.5906 - accuracy: 0.0011\n",
      "Epoch 34/90\n",
      "36139/36139 [==============================] - 5s 138us/step - loss: 588.5409 - accuracy: 0.0011\n",
      "Epoch 35/90\n",
      "36139/36139 [==============================] - 4s 99us/step - loss: 587.9950 - accuracy: 0.0013\n",
      "Epoch 36/90\n",
      "36139/36139 [==============================] - 3s 95us/step - loss: 587.0861 - accuracy: 0.0012\n",
      "Epoch 37/90\n",
      "36139/36139 [==============================] - 4s 115us/step - loss: 586.2485 - accuracy: 0.0013\n",
      "Epoch 38/90\n",
      "36139/36139 [==============================] - 3s 91us/step - loss: 585.5937 - accuracy: 0.0014\n",
      "Epoch 39/90\n",
      "36139/36139 [==============================] - 3s 87us/step - loss: 585.1885 - accuracy: 0.0014\n",
      "Epoch 40/90\n",
      "36139/36139 [==============================] - 3s 77us/step - loss: 584.7440 - accuracy: 0.0014\n",
      "Epoch 41/90\n",
      "36139/36139 [==============================] - 3s 76us/step - loss: 584.2199 - accuracy: 0.0011\n",
      "Epoch 42/90\n",
      "36139/36139 [==============================] - 3s 77us/step - loss: 584.0709 - accuracy: 0.0013\n",
      "Epoch 43/90\n",
      "36139/36139 [==============================] - 3s 75us/step - loss: 583.8422 - accuracy: 0.0013\n",
      "Epoch 44/90\n",
      "36139/36139 [==============================] - 3s 78us/step - loss: 583.6621 - accuracy: 0.0014\n",
      "Epoch 45/90\n",
      "36139/36139 [==============================] - 3s 74us/step - loss: 583.4139 - accuracy: 0.0011\n",
      "Epoch 46/90\n",
      "36139/36139 [==============================] - 3s 76us/step - loss: 583.2826 - accuracy: 0.0012A: 1s -\n",
      "Epoch 47/90\n",
      "36139/36139 [==============================] - 3s 82us/step - loss: 583.1835 - accuracy: 0.0014\n",
      "Epoch 48/90\n",
      "36139/36139 [==============================] - 3s 86us/step - loss: 583.0891 - accuracy: 0.0011\n",
      "Epoch 49/90\n",
      "36139/36139 [==============================] - 3s 86us/step - loss: 582.8451 - accuracy: 0.0017\n",
      "Epoch 50/90\n",
      "36139/36139 [==============================] - 3s 86us/step - loss: 582.7364 - accuracy: 0.0013\n",
      "Epoch 51/90\n",
      "36139/36139 [==============================] - 3s 83us/step - loss: 582.6992 - accuracy: 9.9615e-04\n",
      "Epoch 52/90\n",
      "36139/36139 [==============================] - 3s 81us/step - loss: 582.5203 - accuracy: 0.0011\n",
      "Epoch 53/90\n",
      "36139/36139 [==============================] - 3s 83us/step - loss: 582.2902 - accuracy: 0.0013\n",
      "Epoch 54/90\n",
      "36139/36139 [==============================] - 3s 89us/step - loss: 582.2898 - accuracy: 9.9615e-04\n",
      "Epoch 55/90\n",
      "36139/36139 [==============================] - 5s 125us/step - loss: 582.1463 - accuracy: 0.0012\n",
      "Epoch 56/90\n",
      "36139/36139 [==============================] - 3s 90us/step - loss: 582.0857 - accuracy: 0.0013\n",
      "Epoch 57/90\n",
      "36139/36139 [==============================] - 3s 91us/step - loss: 582.2257 - accuracy: 0.0012\n",
      "Epoch 58/90\n",
      "36139/36139 [==============================] - 3s 88us/step - loss: 582.1568 - accuracy: 0.0013\n",
      "Epoch 59/90\n",
      "36139/36139 [==============================] - 3s 86us/step - loss: 581.8281 - accuracy: 0.0012\n",
      "Epoch 60/90\n",
      "36139/36139 [==============================] - 3s 94us/step - loss: 581.9488 - accuracy: 0.0015\n",
      "Epoch 61/90\n",
      "36139/36139 [==============================] - 4s 120us/step - loss: 581.7709 - accuracy: 0.0012\n",
      "Epoch 62/90\n",
      "36139/36139 [==============================] - 4s 115us/step - loss: 581.8261 - accuracy: 0.0016\n",
      "Epoch 63/90\n",
      "36139/36139 [==============================] - 4s 103us/step - loss: 581.7527 - accuracy: 0.0016\n",
      "Epoch 64/90\n",
      "36139/36139 [==============================] - 3s 88us/step - loss: 581.8203 - accuracy: 0.0011\n",
      "Epoch 65/90\n",
      "36139/36139 [==============================] - 3s 75us/step - loss: 581.6027 - accuracy: 0.0015\n",
      "Epoch 66/90\n",
      "36139/36139 [==============================] - 3s 77us/step - loss: 581.5574 - accuracy: 0.0014\n",
      "Epoch 67/90\n",
      "36139/36139 [==============================] - 3s 92us/step - loss: 581.5427 - accuracy: 0.0010\n",
      "Epoch 68/90\n",
      "36139/36139 [==============================] - 3s 90us/step - loss: 581.5063 - accuracy: 0.0013\n",
      "Epoch 69/90\n",
      "36139/36139 [==============================] - 3s 85us/step - loss: 581.3163 - accuracy: 0.0011\n",
      "Epoch 70/90\n",
      "36139/36139 [==============================] - 3s 85us/step - loss: 581.1265 - accuracy: 0.0013\n",
      "Epoch 71/90\n",
      "36139/36139 [==============================] - 3s 85us/step - loss: 581.2305 - accuracy: 0.0012\n",
      "Epoch 72/90\n",
      "36139/36139 [==============================] - 3s 79us/step - loss: 581.1682 - accuracy: 0.0015\n",
      "Epoch 73/90\n",
      "36139/36139 [==============================] - 3s 80us/step - loss: 581.0039 - accuracy: 0.0011\n",
      "Epoch 74/90\n",
      "36139/36139 [==============================] - 3s 79us/step - loss: 581.1528 - accuracy: 0.0013\n",
      "Epoch 75/90\n",
      "36139/36139 [==============================] - 3s 87us/step - loss: 581.0622 - accuracy: 0.0014\n",
      "Epoch 76/90\n",
      "36139/36139 [==============================] - 4s 107us/step - loss: 580.7566 - accuracy: 0.0015\n",
      "Epoch 77/90\n",
      "36139/36139 [==============================] - 3s 94us/step - loss: 580.8947 - accuracy: 0.0012\n",
      "Epoch 78/90\n",
      "36139/36139 [==============================] - 3s 89us/step - loss: 580.7886 - accuracy: 9.1314e-04\n",
      "Epoch 79/90\n",
      "36139/36139 [==============================] - 3s 89us/step - loss: 580.7756 - accuracy: 0.0010\n",
      "Epoch 80/90\n",
      "36139/36139 [==============================] - 3s 96us/step - loss: 580.8157 - accuracy: 0.0011\n",
      "Epoch 81/90\n",
      "36139/36139 [==============================] - 3s 86us/step - loss: 580.8307 - accuracy: 0.0011\n",
      "Epoch 82/90\n",
      "36139/36139 [==============================] - ETA: 0s - loss: 581.3460 - accuracy: 0.00 - 3s 82us/step - loss: 580.7693 - accuracy: 0.0015\n",
      "Epoch 83/90\n",
      "36139/36139 [==============================] - 3s 89us/step - loss: 580.6693 - accuracy: 0.0015\n",
      "Epoch 84/90\n",
      "36139/36139 [==============================] - 3s 85us/step - loss: 580.5623 - accuracy: 0.0014\n",
      "Epoch 85/90\n",
      "36139/36139 [==============================] - 3s 76us/step - loss: 580.5581 - accuracy: 0.0012\n",
      "Epoch 86/90\n",
      "36139/36139 [==============================] - 3s 74us/step - loss: 580.4539 - accuracy: 0.0014\n",
      "Epoch 87/90\n",
      "36139/36139 [==============================] - 3s 74us/step - loss: 580.5864 - accuracy: 0.0018\n",
      "Epoch 88/90\n",
      "36139/36139 [==============================] - 3s 76us/step - loss: 580.3019 - accuracy: 0.0016\n",
      "Epoch 89/90\n",
      "36139/36139 [==============================] - 3s 80us/step - loss: 580.3915 - accuracy: 0.0012\n",
      "Epoch 90/90\n",
      "36139/36139 [==============================] - 3s 81us/step - loss: 580.2879 - accuracy: 0.0012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x181640be588>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting artifical neural network to the training set\n",
    "regressor.fit(X_train, y_train, batch_size = 10, epochs = 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7mujj_4tAJQ2"
   },
   "source": [
    "# 5. Predicting Results & Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "du15g0OVAJQ2"
   },
   "source": [
    "Now the model has already run, and I will create a variable, y_pred to store the machine’s predictions. For this, I used the Predict method on the X_test dataset to get values corresponding to y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "FW7nKpEuAJQ4",
    "outputId": "d6eac02b-1996-4e0b-ab33-bf33e0890976"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  432.82385],\n",
       "       [ 2126.3196 ],\n",
       "       [ 1311.3177 ],\n",
       "       [ 1460.663  ],\n",
       "       [11893.414  ],\n",
       "       [ 4820.8013 ],\n",
       "       [ 1542.7994 ],\n",
       "       [ 1812.9982 ],\n",
       "       [ 2230.1882 ],\n",
       "       [ 5264.267  ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iQFMPDVXAJQ9"
   },
   "source": [
    "## 5.1. The accuracy, mse, rmse and mae of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GFAV3OXYAJQ9",
    "outputId": "fa1ec41b-1997-4bff-8048-e29847aed184"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9186743904364041"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy\n",
    "from sklearn.metrics import r2_score\n",
    "Accuracy = r2_score(y_test, y_pred)\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cA2m7I34AJRC",
    "outputId": "2d6f73b0-7168-48ec-a1be-832e2fa88bd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1126.8183118546062"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "MSE = mean_squared_error(y_pred, y_test)\n",
    "RMSE = np.sqrt(MSE)\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vpYMVQj9AJRH",
    "outputId": "ec42183b-766b-4590-a1cd-9336b9ac3e4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "566.2885053073293"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MAE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "MAE = mean_absolute_error(y_pred, y_test)\n",
    "MAE"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Roi Polanitzer - how to build a ANN from scratch in Python.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
